{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42249025",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align: center;\">1 Setup</h1>\n",
    "\n",
    "You shoud install python first if you do not have one:\n",
    "\n",
    "Go to https://www.python.org/downloads/ and download Python 3.10/3.11\n",
    "\n",
    "For required packages:\n",
    "\n",
    "### pip install notebook\n",
    "### pip install matplotlib\n",
    "### pip install wordcloud\n",
    "Then you can type:\n",
    "### jupyter notebook\n",
    "For more details, you can access: https://www.nltk.org/book/ch01.html and https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3abc3f",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">1.1 Getting Started with Python</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfe3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 1 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc13af",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">1.2 Getting Started with NLTK</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd4405",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# before import you should install nltk\n",
    "import nltk\n",
    "# download all datasets in nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebd727",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# from NLTK's book module, load all items.\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f06be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# enter their names at the Python prompt\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbc84b",
   "metadata": {},
   "source": [
    "![Moby-Dick](figs/moby-dick.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a2be6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0752053",
   "metadata": {},
   "source": [
    "![Sense and sensibility](figs/sense-and-sensibility.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03460a2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align: center;\">2 Python: Texts as Lists of Words</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897b638",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2 style=\"text-align: center;\">2.1 Lists</h2>\n",
    "What is a text? At one level, it is a sequence of symbols on a page such as this one. At another level, it is a sequence of chapters, made up of a sequence of sections, where each section is a sequence of paragraphs, and so on. However, for our purposes, we will think of a text as nothing more than a sequence of words and punctuation. Here's how we represent text in Python, in this case the opening sentence of Moby Dick:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc5f37",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e41335",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Task: ask for len of this sent1\n",
    "len(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: list out more defined sentences in nltk.book\n",
    "print(sent2)\n",
    "print(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: make a concatenation of two lists\n",
    "print(sent2 + sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43005735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: append a word to a list and then delete this\n",
    "print(sent1)\n",
    "sent1.append(\"NLP\")\n",
    "print(sent1)\n",
    "sent1.pop()\n",
    "print(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887dbc0",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">2.2 Indexing Lists</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find the word at the position 173 in \n",
    "#       US presidential inaugural address texts (text4)\n",
    "print(text4)\n",
    "text4[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: index the word \"awaken\" of its first occurs\n",
    "text4.index('awaken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a188072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: index the word \"NLP\"\n",
    "text4.index('NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514910e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: slicing, index a sublist from 16715 to 16735 starting from \n",
    "#       the beginning of text5 (Chat Corpus)\n",
    "print(text5[16715:16735])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: slicing, index a sublist from 9850 to 9888 starting from the end of text4\n",
    "print(' '.join(text4[-9888:-9850]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: index sublist from position 141525 to the last word\n",
    "print(text2[141525:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf04c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: index the last 3 words\n",
    "print(text2[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: index a sublist word from sent1\n",
    "print(sent1[10:12])\n",
    "print(sent1[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a64e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: create a new variable, an artificial sentence\n",
    "sent = [f'word{_+1}' for _ in range(10)]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7610bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find the first 5 words\n",
    "print(sent[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78015b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: modify the first and last element\n",
    "print(sent)\n",
    "sent[0] = 'First'\n",
    "sent[9] = 'Last'\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29946cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: modify the sublist to a smaller list\n",
    "sent[1:9] = ['Second', 'Third']\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b4398",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">2.3 Variables</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d77872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: define a variable and a sub list of my_sent,\n",
    "#       and then sort the sublist\n",
    "my_sent = ['Bravely', 'bold', 'Sir', 'Robin', ',', 'rode', 'forth', 'from', 'Camelot', '.']\n",
    "noun_phrase = my_sent[1:4]\n",
    "print(noun_phrase)\n",
    "print(sorted(noun_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe107125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find the set of vocabularies of corpus text1 (Moby-Dick)\n",
    "#       list out first 10 words and show the vocabulary size\n",
    "vocab = set(text1)\n",
    "print(list(vocab)[:10])\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45857a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: valid the following new variables\n",
    "not = 'Camelot'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424663b3",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">2.3 Strings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Define a string and find first and last char of it.\n",
    "name = 'Monty'\n",
    "print(name)\n",
    "print(name[0])\n",
    "print(name[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: multiply 2 of name; add it with '!!!':\n",
    "print(name * 2)\n",
    "print(name + \"!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: join the words of a list to make a single string\n",
    "joint_str = ' '.join(['Python', 'for', 'NLP'])\n",
    "print(joint_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de628ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: split a string into a list of words based on a splitter\n",
    "print(joint_str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803a9dc",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">3 Computing with Language: Simple Statistics</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084b9cb",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">3.1 Frequency Distributions</h2>\n",
    "\n",
    "Frequency distribution tells us the frequency of each vocabulary in the text. It is a \"distribution\" because it tells us how the total number of word tokens in the text are distributed across the vocabulary items. Since we often need frequency distributions in language processing, NLTK provides built-in support for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: create a frequency distribution for text1 (Moby-Dick text)\n",
    "\n",
    "# A frequency distribution for the outcomes of an experiment. A frequency distribution \n",
    "# records the number of times each outcome of an experiment has occurred. For example, \n",
    "# a frequency distribution could be used to record the frequency of each word type in \n",
    "# a document. \n",
    "\n",
    "fdist1 = FreqDist(text1)\n",
    "print(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find the 50 most frequent words of text1\n",
    "print(fdist1.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find the frequency of word 'whale' in text1\n",
    "print(fdist1['whale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: plot Cumulative Frequency Plot for 50 Most Frequently Words in Moby Dick\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "font = {'weight' : 'bold', 'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 8)\n",
    "fdist1.plot(50, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: plot Probability Density Function\n",
    "fdist1.plot(50, cumulative=False)\n",
    "# What do you find ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d073e15",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">3.2 Fine-grained Selection of Words</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: look at the long words of the book Moby-Dick (text1)\n",
    "#       find all words that have at least 15 chars.\n",
    "V = set(text1)\n",
    "long_words = [w for w in V if len(w) > 15]\n",
    "print(sorted(long_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8541128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: look at the long words of the Inaugural Address Corpus (text4)\n",
    "#       find all words that have at least 15 chars.\n",
    "V = set(text4)\n",
    "long_words = [w for w in V if len(w) > 15]\n",
    "print(sorted(long_words))\n",
    "\n",
    "# What do you find ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a53aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find all long words of text5\n",
    "print(sorted([w for w in set(text5) if len(w) > 15]))\n",
    "\n",
    "# What do you find ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ec0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find frequently occurring long words. \n",
    "fdist5 = FreqDist(text5)\n",
    "print(sorted(w for w in set(text5) if len(w) > 7 and fdist5[w] > 7))\n",
    "\n",
    "# do you find ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb493a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find hapaxes (hapax legomenon, 孤立词，文本中出现一次)\n",
    "fdist1 = FreqDist(text1)\n",
    "hapax = fdist1.hapaxes()\n",
    "print(hapax[:10])\n",
    "\n",
    "# What do you find ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab106692",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">3.3 Collocations and Bigrams</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: generate bigrams from a word list\n",
    "# A collocation is a sequence of words that occur together unusually often. \n",
    "# Thus red wine is a collocation,  whereas the wine is not.\n",
    "list(bigrams(['more', 'is', 'said', 'than', 'done']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find frequent bigrams of text4 (Inaugural Address Corpus)\n",
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find frequent bigrams of text8 (Personals Corpus \n",
    "#       comes from personal ads posted on various online \n",
    "#       dating sites)\n",
    "text8.collocations() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1d648",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">3.4 Counting Other Things</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eed3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find and cluster frequency of word length\n",
    "\n",
    "# For example, we can look at the distribution of word lengths \n",
    "# in a text, by creating a FreqDist out of a long list of numbers, \n",
    "# where each number is the length of the corresponding word in the text:\n",
    "\n",
    "fdist = FreqDist(len(w) for w in text1)\n",
    "print(fdist)\n",
    "fdist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: show all frequent of the different lengths of words\n",
    "fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find a specific frequency the most frequency length\n",
    "print(fdist.max())\n",
    "print(fdist[3])\n",
    "print(fdist.freq(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ba4b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Functions Defined for NLTK's Frequency Distributions](figs/freq-dist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915864a",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">4 Python: Making Decisions and Taking Control</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1b41e",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">4.1 Numerical Comparison Operators</h2>\n",
    "\n",
    "![dd](figs/operations.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab21a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: find shorter and longer words\n",
    "print(sent7)\n",
    "print([w for w in sent7 if len(w) < 4])\n",
    "print([w for w in sent7 if len(w) >= 4])\n",
    "print([w for w in sent7 if len(w) == 4])\n",
    "print([w for w in sent7 if len(w) != 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: what is this ?\n",
    "print(sorted(w for w in set(text1) if w.endswith('ableness'))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: what is this ?\n",
    "print(sorted(term for term in set(text4) if 'gnt' in term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: what is this ?\n",
    "print(sorted(item for item in set(text6) if item.istitle())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eadd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: what is this ?\n",
    "print(sorted(item for item in set(sent7) if item.isdigit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(w for w in set(text7) if '-' in w and 'index' in w))\n",
    "print(sorted(wd for wd in set(text3) if wd.istitle() and len(wd) > 10))\n",
    "print(sorted(w for w in set(sent7) if not w.islower()))\n",
    "print(sorted(t for t in set(text2) if 'cie' in t or 'cei' in t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "captical_words = [w.upper() for w in text1]\n",
    "print(captical_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75680d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text1)\n",
    "print(len(text1))\n",
    "print(len(set(text1)))\n",
    "print(len(set(word.lower() for word in text1)))\n",
    "# merge words like The the."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab38235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate numbers and punctuation from the vocabulary count by \n",
    "# filtering out any non-alphabetic items:\n",
    "print(len(set(word.lower() for word in text1 if word.isalpha())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dafeb00",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">4.2 Nested Code Blocks</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If condition\n",
    "word = 'cat'\n",
    "if len(word) < 5:\n",
    "    print('word length is less than 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab33eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop\n",
    "for word in ['Call', 'me', 'Baojian', '.']:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8772ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the word type for sent1\n",
    "for token in sent1:\n",
    "    if token.islower():\n",
    "        print(f'{token:10} is a lowercase word')\n",
    "    elif token.istitle():\n",
    "        print(f'{token:10} is a titlecase word')\n",
    "    else:\n",
    "        print(f'{token:10} is punctuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of cie and cei words, \n",
    "# then we loop over each item and print it. \n",
    "tricky = sorted(w for w in set(text2) if 'cie' in w or 'cei' in w)\n",
    "for word in tricky:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8215f",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">5 Automatic Natural Language Understanding</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1a0b9",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">5.1 Searching Text</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae10b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: look up the context of word \"monstrous\" in Moby Dick (text1) \n",
    "print('-'*17)\n",
    "text1.concordance(\"monstrous\")\n",
    "print('-'*17)\n",
    "text1.concordance(\"fudan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05889bfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: search Sense and Sensibility (text2) for the word \"affection\"\n",
    "print('-'*17)\n",
    "text2.concordance(\"affection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73aa758",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: search the book of Genesis (text3) to find out how long some people lived\n",
    "text3.concordance(\"lived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22b96b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: look at text4, the Inaugural Address Corpus, to see examples of English going back to 1789, \n",
    "print('-'*17)\n",
    "text4.concordance(\"nation\")\n",
    "print('-'*17)\n",
    "text4.concordance(\"terror\")\n",
    "# see how these words have been used differently over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8c695",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: find lol context in text5, the NPS Chat Corpus: \n",
    "#       search this for unconventional words like im, ur, lol.\n",
    "text5.concordance(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e8559",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: find similar context,\n",
    "#.      we saw that monstrous occurred in contexts such as \n",
    "#.      the ___ pictures and a ___ size. What other words \n",
    "#.      appear in a similar range of contexts?\n",
    "text1.concordance(\"monstrous\")\n",
    "print('-'*17)\n",
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cfa28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: find similar context of monstrous in text2\n",
    "text2.concordance(\"monstrous\")\n",
    "print('-'*17)\n",
    "text2.similar(\"monstrous\")\n",
    "\n",
    "# Observe that we get different results for different texts. \n",
    "# Austen uses this word quite differently from Melville; \n",
    "# for her, monstrous has positive connotations, and sometimes \n",
    "# functions as an intensifier like the word very."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196f1ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: find common context of two words\n",
    "# The term \"common_contexts\" allows us to examine \n",
    "# just the contexts that are shared by two or more words\n",
    "text1.common_contexts([\"monstrous\", \"very\"])\n",
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d60ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: determine the location of a word in the text: \n",
    "# how many words from the beginning it appears. \n",
    "# This positional information can be displayed using a dispersion plot. \n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff1d3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: show the dispersion plot for Elinor, Edward, Marianne, Willoughby\n",
    "text2.dispersion_plot([\"Elinor\", \"Edward\", \"Marianne\", \"Willoughby\"])\n",
    "# TODO: There is a bug in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: generate some random text in the various styles we have just seen.\n",
    "text3.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ca6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: generate word cloud\n",
    "#.      you may need to install wordcloud first\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import sys\n",
    "!{sys.executable} -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in text1]\n",
    "fd = nltk.FreqDist(words).most_common()\n",
    "wc = WordCloud(background_color='white', max_words=2000, stopwords=STOPWORDS, max_font_size=50,\n",
    "              random_state=17)\n",
    "wc.generate(' '.join(words))\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d30158",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Task: create a new function\n",
    "def dispersion_plot(text, words, ignore_case=False, title=\"Lexical Dispersion Plot\"):\n",
    "    \"\"\"\n",
    "    Generate a lexical dispersion plot.\n",
    "\n",
    "    :param text: The source text\n",
    "    :type text: list(str) or iter(str)\n",
    "    :param words: The target words\n",
    "    :type words: list of str\n",
    "    :param ignore_case: flag to set if case should be ignored when searching text\n",
    "    :type ignore_case: bool\n",
    "    :return: a matplotlib Axes object that may still be modified before plotting\n",
    "    :rtype: Axes\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError as e:\n",
    "        raise ImportError(\n",
    "            \"The plot function requires matplotlib to be installed. \"\n",
    "            \"See https://matplotlib.org/\"\n",
    "        ) from e\n",
    "\n",
    "    word2y = {\n",
    "        word.casefold() if ignore_case else word: y\n",
    "        for y, word in enumerate(reversed(words)) # should not be reversed(words)\n",
    "    }\n",
    "    xs, ys = [], []\n",
    "    for x, token in enumerate(text):\n",
    "        token = token.casefold() if ignore_case else token\n",
    "        y = word2y.get(token)\n",
    "        if y is not None:\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "    ax.plot(xs, ys, \"|\")\n",
    "    ax.set_yticks(list(range(len(words))), reversed(words), color=\"C0\") # or put revered here.\n",
    "    ax.set_ylim(-1, len(words))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Word Offset\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "words = [\"Elinor\", \"Marianne\", \"Edward\", \"Willoughby\"]\n",
    "dispersion_plot(gutenberg.words(\"austen-sense.txt\"), words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420d342",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">5.2 Counting words</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acda77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: count how many words (including punctuation symbols) in the book of Genesis\n",
    "len(text3)\n",
    "# So Genesis has 44,764 words and punctuation symbols, or \"tokens.\" \n",
    "# A token is the technical name for a sequence of characters — \n",
    "# such as hairy, his, or :) — that we want to treat as a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdacdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: calculate a measure of the lexical richness of the text. \n",
    "print(f\"{len(set(text3)) / len(text3) * 100:.2f}%\")\n",
    "# the number of distinct words is just 6% of the total number of words, \n",
    "# or equivalently that each word is used 16 times on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: count a specific word a\n",
    "print(text3.count(\"the\"))\n",
    "print('-'*17)\n",
    "# count percentage of the word \"a\" used in the book\n",
    "val = 100 * text4.count(r\"a\") / len(text4)\n",
    "print(f\"{val:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712954f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: counting lol\n",
    "print(text1.count(\"lol\"))\n",
    "print(text2.count(\"lol\"))\n",
    "print(text3.count(\"lol\"))\n",
    "print(text4.count(\"lol\"))\n",
    "print(text5.count(\"lol\"))\n",
    "print(text6.count(\"lol\"))\n",
    "# text5 is a corpus of Online Chat Dialogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d4339",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">5.3 Gutenberg Corpus</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714f04ef",
   "metadata": {},
   "source": [
    "NLTK includes a small selection of texts from the Project Gutenberg electronic text archive, which contains some 25,000 free electronic books, hosted at http://www.gutenberg.org/. We begin by getting the Python interpreter to load the NLTK package, then ask to see nltk.corpus.gutenberg.fileids(), the file identifiers in this corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick out the first of these texts — Emma by Jane Austen — \n",
    "# and give it a short name, emma, then  find out how many words \n",
    "# it contains\n",
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d0a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
    "emma.concordance(\"surprize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb76129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    num_vocab = len(set(w.lower() for w in gutenberg.words(fileid)))\n",
    "    print(round(num_chars/num_words), round(num_words/num_sents), round(num_words/num_vocab), fileid)\n",
    "# average word length, average sentence length,\n",
    "# and the number of times each vocabulary item appears \n",
    "# in the text on average (our lexical diversity score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14af4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "print(macbeth_sentences)\n",
    "print(macbeth_sentences[1116])\n",
    "longest_len = max(len(s) for s in macbeth_sentences)\n",
    "print([s for s in macbeth_sentences if len(s) == longest_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcacdc",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">5.4 Web and Chat Text</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f023d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5568b4-6fde-409f-8948-eb4b63b6eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
